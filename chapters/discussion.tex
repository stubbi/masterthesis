\chapter{Conclusion and Discussion}

The results of the experiments show that RBMs are able to simulate random circuit 
instances with 4 qubits and a depth of up to 20 cycles accurately. The comparison of 
Stochastic Reconfiguration and AdaMax as optimization algorithms suggests that 
AdaMax is better suited for the given gate set and circuit structure with the chosen training 
parameters. 

The bad performance of the SR methods might be grounded in the algorithm getting stuck in 
local minima. The oscillation for SR could be explained by the algorithm finding an 
optimum one one training batch which does not generalize well to the other training samples.
This would also explain why there is no oscillations for SR with restarts on 8 samples. In that
cases, all training samples are inside the same batch. Increasing the batch size or lowering the 
number of hidden units together with random restarts could improve the performance of the SR algorithm.

Using SR with random restarts had only small if any 
impact on the resulting accuracy of the RBMs although the testing and training overlap 
loo different during the training process. This does not imply that this would also 
hold for AdaMax. Indeed, pre-studies suggested that random restarts might have a positive 
impact on the RBM's accuracy when trained with AdaMax.


The training and testing overlaps for AdaMax show that the single-qubit gates can 
be learned within less than 100 training iterations. Applying 
the $CZ$ gates directly will omit the need for more training iterations for the given RBM size.

Further, it seems that the more training samples are available, the better the RBM will 
perform when trained with AdaMax. For this parameter, more experiments will be necessary 
to understand how the number of samples scales with the number of qubits. Establishing
a relation between the number of training samples and the resulting gate fidelity would 
be a major step in understanding the capabilities of RBMs for the classical simulation of 
quantum systems.

In the conducted experiments, 303 samples were enough to sample each configuration of the 
$2^n$ dimensional state space multiple times. Only for 8  samples, not the full state space
had a chance to be observed for the training. The performance of the RBMs with 8 samples only 
had been very low. Only if RBMs can achieve acceptable performance with a number of samples 
that does not scale exponentially with the number of qubits, this approach would be useful for 
real world applications. 

In this regard, this study lacks on interpretable insights. Rather than making use of the 
Coupon-collectors problem, it would have been possible to train the RBMs with less samples. 
The training and test sets could have been made up of a defined number of certainly different 
samples. This might have given clearer insights into the relation between the ratio of the 
state space observed and the resulting RBM performance. For future research, the samples should
be drawn that way.

Acceptable performance does not imply perfect simulations. Noisy simulations with 
fidelities in the range of that from the Sycamore processor could help to understand the 
capabilities and limits of NISQ devices. For 10 qubits, for instance, the cross-entropy fidelity
of the Sycamore processor was estimated to be around 0.4. On the 4 qubit circuits with 
15 cycles, the fidelity is about 0.9.

Nevertheless, the results also show that there is no direct link between the cross-entropy
fidelity and the total variation distance. Under the assumption that the output strings of 
the circuit are Porter-Thomas distributed, the cross-entropy fidelity is a suitable metric
when not all $2^n$ amplitudes can be accessed directly. This is the case for quantum devices, 
where it is only possible to infer the outcome probabilities by drawing samples from the computer.
As the distribution of the circuit might differ from the Porter-Thomas distribution, 
the fidelity can only be a lower bound for the fidelity of a quantum circuit simulation.
For AdaMax, the cross-entropy between the RBM's output and the exact output was 
higher when also the cross-entropy between the exact output and a perfect Porter-Thomas 
distribution was higher.

Understanding the performance on a wider range of qubits was already intended for this work. 
However, the performed experiments 
on 4 qubit random circuits took already 8 weeks. Maintenance work on the Noctua Cluster 
afterwards made it impossible to conduct more experiments on a wider range of qubits.
Nevertheless, the software developed in the progress of this work is available open source. 
This makes it easy to adapt the code to conduct experiments 
with other ranges of parameters and quantum circuits. For the given kind of random circuit 
sampling experiments, everything is set up to perform more experiments on a broader range of 
qubits.

The framework can also be easily used to simulate other NISQ algorithms. This could help to 
understand such algorithms when no device is available and how the algorithm
behaves with different levels of noise in the computation.

Another interesting research direction might be 
to understand how RBMs with complex parameters compare to RBMs with real parameters. Can they 
represent probability distribution real valued RBMs cannot represent or hardly represent? What 
about training performance for distributions both could represent?

All in all a starting point for a novel classical approximation technique for quantum computing.
The software is available and can read quantum circuits as inputs in QASM format. The results from 
this study give a reference for good training parameters which have not been included in related work.


